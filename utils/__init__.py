"""
é¡¹ç›®å·¥å…·æ¨¡å—
åŒ…å«å„ç§è¾…åŠ©åŠŸèƒ½å’Œå·¥å…·å‡½æ•°
"""

import logging
import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import json
import re
from datetime import datetime

def setup_logging(log_level: str = "INFO", 
                 log_file: Optional[str] = None,
                 log_dir: str = "logs") -> logging.Logger:
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    if log_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = f"grace_{timestamp}.log"
    
    log_path = Path(log_dir)
    log_path.mkdir(exist_ok=True)
    full_log_path = log_path / log_file
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(full_log_path, encoding='utf-8')
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"æ—¥å¿—å·²è®¾ç½®: {full_log_path}")
    return logger

def get_project_root() -> Path:
    """è·å–é¡¹ç›®æ ¹ç›®å½•"""
    return Path(__file__).parent.parent

def create_directory_structure():
    """åˆ›å»ºæ ‡å‡†çš„é¡¹ç›®ç›®å½•ç»“æ„"""
    root = get_project_root()
    
    directories = [
        "config",
        "data/raw",
        "data/processed", 
        "models",
        "utils",
        "logs",
        "output",
        "notebooks",
        "tests"
    ]
    
    for dir_name in directories:
        dir_path = root / dir_name
        dir_path.mkdir(parents=True, exist_ok=True)
        print(f"åˆ›å»ºç›®å½•: {dir_path}")

def validate_code_content(code: str) -> bool:
    """éªŒè¯ä»£ç å†…å®¹æ˜¯å¦æœ‰æ•ˆ"""
    if not code or len(code.strip()) < 10:
        return False
    
    # ç®€å•çš„è¯­æ³•æ£€æŸ¥
    if re.search(r'[^\w\s\.\-\_\(\)\[\]\{\}\;\:\,\=\+\-\*\/\\%<>&\|\!\?]', code):
        # åŒ…å«å¯ç–‘å­—ç¬¦ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥
        pass
    
    return True

def clean_code(code: str) -> str:
    """æ¸…ç†ä»£ç æ–‡æœ¬"""
    if not code:
        return ""
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    lines = code.split('\\n')
    cleaned_lines = []
    
    for line in lines:
        # ç§»é™¤è¡Œé¦–å°¾ç©ºç™½
        cleaned_line = line.strip()
        # è·³è¿‡ç©ºè¡Œ
        if cleaned_line:
            cleaned_lines.append(cleaned_line)
    
    return '\\n'.join(cleaned_lines)

def extract_code_functions(code: str) -> List[str]:
    """ä»ä»£ç ä¸­æå–å‡½æ•°å®šä¹‰"""
    if not code:
        return []
    
    # ç®€å•çš„å‡½æ•°åŒ¹é…æ¨¡å¼
    function_patterns = [
        r'def\\s+(\\w+)\\s*\\([^)]*\\):',  # Python
        r'function\\s+(\\w+)\\s*\\([^)]*\\)',  # JavaScript
        r'(\\w+)\\s*\\([^)]*\\)\\s*{',  # C/Javaç­‰
    ]
    
    functions = []
    for pattern in function_patterns:
        matches = re.findall(pattern, code, re.MULTILINE)
        functions.extend(matches)
    
    return list(set(functions))  # å»é‡

def get_file_info(file_path: str) -> Dict[str, Any]:
    """è·å–æ–‡ä»¶ä¿¡æ¯"""
    path = Path(file_path)
    
    if not path.exists():
        return {"exists": False}
    
    stat = path.stat()
    
    return {
        "exists": True,
        "size": stat.st_size,
        "size_mb": round(stat.st_size / 1024 / 1024, 2),
        "modified_time": datetime.fromtimestamp(stat.st_mtime).isoformat(),
        "extension": path.suffix,
        "is_file": path.is_file(),
        "is_dir": path.is_dir()
    }

def safe_json_load(file_path: str, default: Any = None) -> Any:
    """å®‰å…¨åœ°åŠ è½½JSONæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        logging.warning(f"åŠ è½½JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return default

def safe_json_dump(data: Any, file_path: str) -> bool:
    """å®‰å…¨åœ°ä¿å­˜JSONæ–‡ä»¶"""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        logging.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return False

def estimate_model_size(model_name: str) -> Dict[str, float]:
    """ä¼°ç®—æ¨¡å‹å¤§å°ï¼ˆMBï¼‰"""
    # è¿™é‡Œå¯ä»¥åŸºäºæ¨¡å‹åç§°ä¼°ç®—å¤§å°
    # æˆ–è€…æ£€æŸ¥å®é™…ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶
    
    size_estimates = {
        "microsoft/codebert-base": 440,  # MB
        "microsoft/graphcodebert-base": 440,
        "codet5-base": 220,
        "codet5-small": 60
    }
    
    return {
        "estimated_size_mb": size_estimates.get(model_name, 300),
        "note": "è¿™æ˜¯åŸºäºæ¨¡å‹ç±»å‹çš„ä¼°ç®—å€¼"
    }

def format_model_info(model_data: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–æ¨¡å‹ä¿¡æ¯æ˜¾ç¤º"""
    if not model_data:
        return "æ— æ¨¡å‹ä¿¡æ¯"
    
    lines = []
    lines.append(f"æ¨¡å‹åç§°: {model_data.get('name', 'æœªçŸ¥')}")
    lines.append(f"æ¨¡å‹è·¯å¾„: {model_data.get('path', 'æœªçŸ¥')}")
    lines.append(f"æ–‡ä»¶æ•°é‡: {model_data.get('file_count', 0)}")
    lines.append(f"æ€»å¤§å°: {model_data.get('total_size_mb', 0)} MB")
    
    return "\\n".join(lines)

def create_sample_config() -> Dict[str, Any]:
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    return {
        "model_config": {
            "default_model": "microsoft/codebert-base",
            "max_length": 512,
            "temperature": 0.1
        },
        "data_config": {
            "datasets": {
                "bigvul": {
                    "name": "BigVul",
                    "description": "å¤§å‹è½¯ä»¶æ¼æ´æ•°æ®é›†",
                    "download_url": "https://github.com/microsoft/CodeXGLUE/tree/main/Code-Defect Detection"
                },
                "reveal": {
                    "name": "Reveal", 
                    "description": "ä»£ç æ¼æ´æ£€æµ‹æ•°æ®é›†",
                    "download_url": "https://github.com/jple Phoebe/REVEAL"
                },
                "devign": {
                    "name": "Devign",
                    "description": "å¼€å‘è€…å¼•å…¥çš„æ¼æ´æ•°æ®é›†",
                    "download_url": "https://github.com/duong_LEE/Devign"
                }
            }
        },
        "retrieval_config": {
            "faiss_index_type": "IndexFlatIP",
            "top_k": 5,
            "similarity_threshold": 0.8
        },
        "prompt_config": {
            "default_template": "basic",
            "include_code_context": True,
            "max_examples": 3
        }
    }

def generate_readme_content() -> str:
    """ç”ŸæˆREADMEå†…å®¹"""
    return """# GRACE - åŸºäºå›¾ç»“æ„å’Œä¸Šä¸‹æ–‡å­¦ä¹ çš„LLMæ¼æ´æ£€æµ‹

## é¡¹ç›®ç®€ä»‹

GRACE (Graph structure and in-context learning Enhanced vulnerability detection) æ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è½¯ä»¶æ¼æ´æ£€æµ‹ç³»ç»Ÿï¼Œæ”¯æŒå›¾ç»“æ„ä¿¡æ¯å’Œä¸Šä¸‹æ–‡å­¦ä¹ æ¥æå‡æ£€æµ‹å‡†ç¡®ç‡ã€‚

## ç‰¹æ€§

- ğŸš€ æœ¬åœ°æ¨¡å‹æ¨ç† - æ— éœ€APIä¾èµ–
- ğŸ“Š æ”¯æŒå¤šç§æ•°æ®é›† (BigVul, Reveal, Devign)
- ğŸ” åŸºäºå›¾ç»“æ„çš„ä»£ç åˆ†æ
- ğŸ§  ä¸Šä¸‹æ–‡å­¦ä¹ å’Œç¤ºä¾‹æ£€ç´¢
- ğŸ“ˆ å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡
- ğŸ¯ äº¤äº’å¼æ¼æ´æ£€æµ‹

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

```bash
python main.py --download-model
```

### 3. è¿è¡Œè¯„ä¼°

```bash
python main.py --mode eval --dataset bigvul
```

### 4. äº¤äº’å¼æ£€æµ‹

```bash
python main.py --mode interactive
```

## é¡¹ç›®ç»“æ„

```
GRACE/
â”œâ”€â”€ main.py                 # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py          # é…ç½®æ–‡ä»¶
â”œâ”€â”€ models/
â”‚   â””â”€â”€ __init__.py        # æ¨¡å‹æ¥å£
â”œâ”€â”€ data/
â”‚   â””â”€â”€ __init__.py        # æ•°æ®å¤„ç†
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ model_downloader.py # æ¨¡å‹ä¸‹è½½ç®¡ç†
â”‚   â””â”€â”€ prompt_templates.py # æç¤ºæ¨¡æ¿
â”œâ”€â”€ requirements.txt       # ä¾èµ–æ–‡ä»¶
â””â”€â”€ README.md             # é¡¹ç›®æ–‡æ¡£
```

## é…ç½®è¯´æ˜

ä¸»è¦é…ç½®é¡¹ä½äº `config/config.py`ï¼š

- `model_config`: æ¨¡å‹ç›¸å…³é…ç½®
- `data_config`: æ•°æ®é›†é…ç½®  
- `retrieval_config`: æ£€ç´¢é…ç½®
- `prompt_config`: æç¤ºæ¨¡æ¿é…ç½®

## ä½¿ç”¨ç¤ºä¾‹

### ä»£ç ç¤ºä¾‹

```python
from models import LocalVulnerabilityDetector
from utils.prompt_templates import create_vulnerability_prompt

# åˆå§‹åŒ–æ£€æµ‹å™¨
detector = LocalVulnerabilityDetector("microsoft/codebert-base")

# åˆ›å»ºæ£€æµ‹æç¤º
prompt = create_vulnerability_prompt(code="your_code_here")

# æ‰§è¡Œé¢„æµ‹
result = detector.predict_vulnerability(prompt)
print(result)
```

### å‘½ä»¤è¡Œä½¿ç”¨

```bash
# ä¸‹è½½æ¨¡å‹
python main.py --download-model

# è¯„ä¼°ç‰¹å®šæ•°æ®é›†
python main.py --mode eval --dataset reveal --split test

# äº¤äº’å¼æ¨¡å¼
python main.py --mode interactive
```

## æ”¯æŒçš„æ•°æ®é›†

1. **BigVul**: å¤§å‹è½¯ä»¶æ¼æ´æ•°æ®é›†
2. **Reveal**: ä»£ç æ¼æ´æ£€æµ‹æ•°æ®é›†  
3. **Devign**: å¼€å‘è€…å¼•å…¥çš„æ¼æ´æ•°æ®é›†

## æ€§èƒ½æŒ‡æ ‡

ç³»ç»Ÿåœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼š

- BigVul: Accuracy 0.9169, F1 0.3593
- Reveal: Accuracy 0.8812, F1 0.4226
- Devign: Accuracy 0.6013, F1 0.6638

## ä¾èµ–

- Python 3.8+
- PyTorch
- Transformers
- FAISS
- scikit-learn
- pandas

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡ GitHub Issues è”ç³»ã€‚
"""

def check_system_requirements() -> Dict[str, bool]:
    """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚"""
    checks = {
        "python_version": sys.version_info >= (3, 8),
        "torch_available": False,
        "transformers_available": False,
        "faiss_available": False,
        "sklearn_available": False,
        "memory_gte_4gb": False
    }
    
    # æ£€æŸ¥åŒ…æ˜¯å¦å®‰è£…
    try:
        import torch
        checks["torch_available"] = True
    except ImportError:
        pass
    
    try:
        import transformers
        checks["transformers_available"] = True
    except ImportError:
        pass
    
    try:
        import faiss
        checks["faiss_available"] = True
    except ImportError:
        pass
    
    try:
        import sklearn
        checks["sklearn_available"] = True
    except ImportError:
        pass
    
    # æ£€æŸ¥å†…å­˜ï¼ˆç®€å•ä¼°ç®—ï¼‰
    try:
        import psutil
        memory_gb = psutil.virtual_memory().total / (1024**3)
        checks["memory_gte_4gb"] = memory_gb >= 4
    except ImportError:
        # å¦‚æœpsutilä¸å¯ç”¨ï¼Œå‡è®¾æœ‰è¶³å¤Ÿå†…å­˜
        checks["memory_gte_4gb"] = True
    
    return checks

class ProgressBar:
    """ç®€å•çš„è¿›åº¦æ¡"""
    
    def __init__(self, total: int, width: int = 50):
        self.total = total
        self.width = width
        self.current = 0
    
    def update(self, step: int = 1):
        """æ›´æ–°è¿›åº¦"""
        self.current += step
        percent = self.current / self.total
        filled_width = int(self.width * percent)
        
        bar = 'â–ˆ' * filled_width + 'â–‘' * (self.width - filled_width)
        print(f'\\rè¿›åº¦: |{bar}| {percent:.1%} ({self.current}/{self.total})', end='')
        
        if self.current >= self.total:
            print()  # æ¢è¡Œ

def ensure_directories():
    """ç¡®ä¿é¡¹ç›®å¿…è¦çš„ç›®å½•ç»“æ„å­˜åœ¨"""
    root = get_project_root()
    
    required_dirs = [
        root / "config",
        root / "data" / "raw", 
        root / "data" / "processed",
        root / "models",
        root / "utils",
        root / "logs",
        root / "outputs",
        root / "logs"
    ]
    
    for dir_path in required_dirs:
        dir_path.mkdir(parents=True, exist_ok=True)
    
    return True

def save_json_safe(data: Any, file_path: str) -> bool:
    """å®‰å…¨åœ°ä¿å­˜JSONæ–‡ä»¶çš„åˆ«å"""
    return safe_json_dump(data, file_path)

def estimate_model_size(model_name: str) -> float:
    """ä¼°ç®—æ¨¡å‹å¤§å°ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    # åŸºç¡€ä¼°ç®—ï¼šå°å‹æ¨¡å‹çº¦ 100-300MBï¼Œå¤§å‹æ¨¡å‹çº¦ 1-5GB
    size_estimates = {
        "microsoft/codebert-base": 440,  # MB
        "microsoft/graphcodebert-base": 440,
        "codet5-base": 220,
        "codet5-small": 60
    }
    return size_estimates.get(model_name, 300)

# å¯¼å‡ºä¸»è¦å‡½æ•°
__all__ = [
    'setup_logging',
    'get_project_root', 
    'create_directory_structure',
    'ensure_directories',
    'validate_code_content',
    'clean_code',
    'get_file_info',
    'safe_json_load',
    'safe_json_dump',
    'save_json_safe',
    'create_sample_config',
    'generate_readme_content',
    'check_system_requirements',
    'ProgressBar',
    'estimate_model_size'
]